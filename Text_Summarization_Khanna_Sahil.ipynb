{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86aafaef",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9f581",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf53311b-3101-40ba-abe4-530ec1052619",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-loading the model before data source to optimize memory \n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L-12-v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf01775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "import nltk\n",
    "import faiss\n",
    "import time\n",
    "\n",
    "# define a search \n",
    "def search(query, model, text_list):\n",
    "    \n",
    "    t=time.time()\n",
    "    query_vector = model.encode([query])\n",
    "    k = 5\n",
    "    top_k = index.search(query_vector, k)\n",
    "    print('totaltime: {}'.format(time.time()-t))\n",
    "    return [text_list[_id] for _id in top_k[1].tolist()[0]]\n",
    "    \n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "LANGUAGE = \"english\"\n",
    "stemmer = Stemmer(LANGUAGE)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models #don't skip this \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess(textstring):\n",
    "   stops =  set(stopwords.words('english'))\n",
    "   tokens = word_tokenize(textstring)\n",
    "   return [token.lower() for token in tokens if token.isalpha() \n",
    "          and token not in stops]\n",
    "\n",
    "from rouge_score import rouge_scorer\n",
    "def print_rouge_score(rouge_score):\n",
    "    for k,v in rouge_score.items():\n",
    "        print (k, 'Precision:', \"{:.2f}\".format(v.precision), 'Recall:', \"{:.2f}\".format(v.recall), 'fmeasure:', \"{:.2f}\".format(v.fmeasure))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce4acb-2af2-4f10-8995-b24771e65e8a",
   "metadata": {},
   "source": [
    "## Text Soruces\n",
    "\n",
    "* This text source is a Wireland ranch episode 1 podcast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784015f5-88e7-40c7-bfdb-431e49387b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: The Return of the Overseer FEMALE VOICE (hissing whispers underlay the voice): Welcome Overseer . It has been an unusually long time. It’s… [she hesitates as though *nice* is not the proper descriptor for the complex palette of emotions this moment has conjured] …*interesting* to see you again. The overseer opens his eyes, the lids heavy , weighed down by a dogged stubborn sleep still trying to drag him back into the beckoning arms of a slumber from which he’d just awoken. He finds he feels more *revived* than he does *awake*, as though the act of opening his eyes had done more than process light into images in his visual cortex but also maybe… and this thought arrives with a shudder , maybe… saved his life? FEMALE VOICE: Do you know where you are? He did not. And as his eyes adjusted to his surroundings he began to question if he even *wanted* to know . Some things are, after all, unknowable and this room he finds himself in seems to fit snugly into that category . But you and I, friends, the limits of knowing do not extend to us *as we are the witnesses*, and by the end, we will all have a slightly different story to tell. Before we know this room though, this room on the dividing line of everything and a nothing so complete the word nothing doesn’ t even begin to define it, we must know the arrival. (Female voice in background: “byeeeee!”) (DOOR DASH CHIME starting normal and slowly devolving as the statement moves forward.)  The chime seemed different on the last delivery he made. The bright focus group approved. Pavlovian dinging that ushered slave wage delivery terms onto his screen was muted and slow,\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf file object\n",
    "pdfFileObj = open('wireland_ranch.pdf', 'rb')\n",
    "  \n",
    "# creating a pdf reader object\n",
    "pdfReader = PyPDF2.PdfReader(pdfFileObj)\n",
    "  \n",
    "# printing number of pages in pdf file\n",
    "len(pdfReader.pages)\n",
    "\n",
    "# creating a page object\n",
    "pageObj = pdfReader.pages\n",
    "  \n",
    "# extracting text from page\n",
    "# loop here to get it all \n",
    "text = []\n",
    "for page in pageObj:\n",
    "  page = re.sub(\"\\\\n\", \" \", page.extract_text())\n",
    "  text.append(page)\n",
    "  \n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f167872b-efdc-4517-b9eb-c7dec5b849d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Episode 1: The Return of the Overseer FEMALE V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has been an unusually long time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It’s… [she hesitates as though *nice* is not t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The overseer opens his eyes, the lids heavy , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He finds he feels more *revived* than he does ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0  Episode 1: The Return of the Overseer FEMALE V...\n",
       "1                It has been an unusually long time.\n",
       "2  It’s… [she hesitates as though *nice* is not t...\n",
       "3  The overseer opens his eyes, the lids heavy , ...\n",
       "4  He finds he feels more *revived* than he does ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "len(sentences)\n",
    "\n",
    "DF = pd.DataFrame(sentences, columns = ['sentence'])\n",
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268df1de-27bf-437d-a0c1-fbb58615aaf6",
   "metadata": {},
   "source": [
    "## Create A Search Engine\n",
    "\n",
    "* Using each sentence as my “documents”, I created a search engine to find specific pieces of text.\n",
    "* Search for several items.\n",
    "* Examine the results and comment on how well I think the search engine worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648db68b-71cd-4b8e-8419-0c6e93e0232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need to run this thing once and once it is \n",
    "# saved, you can \"turn off\" the chunk using eval = F in \n",
    "# Rstudio, or change the code type to markdown to save \n",
    "# the code for yourself in datalore but not run it\n",
    "# Load a pre-trained model\n",
    "#model = SentenceTransformer('msmarco-MiniLM-L-12-v3')\n",
    "#wireland_embed = model.encode(DF['sentence'].to_list()) #same as sentences, but helps to have a DF in case you needed to do other cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57de6603-3336-4442-9c05-675cb0d0baf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = DF['sentence'].to_list()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ebf4e53-3493-48fd-a76c-69dfb0fa03f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## breaking the data into 3 smaller batches and processing each batch separately to manage memory usage better.\n",
    "sentences_1 = sentences[0:78]\n",
    "sentences_2 = sentences[78:156]\n",
    "sentences_3 = sentences[156:236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b93637a-dbfe-4747-aba0-c469b13bdb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('msmarco-MiniLM-L-12-v3')\n",
    "embeddings_1 = model.encode(sentences_1)\n",
    "embeddings_2 = model.encode(sentences_2)\n",
    "embeddings_3 = model.encode(sentences_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e3b5244-54b3-4172-b454-f64ac5ec0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Concatenate along the first axis (axis=0)\n",
    "wireland_embed = np.concatenate((embeddings_1, embeddings_2, embeddings_3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41cd99a1-6f07-4ec9-bb31-9d382ecbb09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wireland_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1a955df-d54e-4b82-aed6-009af06baa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index using FAISS\n",
    "index = faiss.IndexFlatL2(wireland_embed.shape[1])\n",
    "index.add(wireland_embed)\n",
    "faiss.write_index(index, 'index_wireland_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fafa0a91-7cc0-4ba0-9e8f-33c4b5f1bf57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totaltime: 0.1043698787689209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The overseer opens his eyes, the lids heavy , weighed down by a dogged stubborn sleep still trying to drag him back into the beckoning arms of a slumber from which he’d just awoken.',\n",
       " 'Episode 1: The Return of the Overseer FEMALE VOICE (hissing whispers underlay the voice): Welcome Overseer .',\n",
       " 'Ignore her overseer , she’s just a dirty girl, is all.',\n",
       " '--- Watch out [he can hear the eyeroll in the everywhere voice] for the majestic Sphinx, Overseer , she has been known to seek attention when she is in heat, which again, can be a doozy if you aren’ t into that sort of thing.',\n",
       " 'And oh dear overseer , you will soon be at the intersection of all that is, and all that is not.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Search for several items. \n",
    "\n",
    "# read in the index later when you need to use this again \n",
    "index = faiss.read_index('index_wireland_reviews')\n",
    "# you do have to have the model open too \n",
    "model = SentenceTransformer('msmarco-MiniLM-L-12-v3')\n",
    "\n",
    "search(\"overseer\", model, DF['sentence'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29bdcb18-3821-4687-97a9-741830df0da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totaltime: 0.09686398506164551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The man in the station wagon stared at him in the rearview mirror , violence flashed in the mans eyes for a moment, the kind of violence only an insurrection or civil war can tame and just as quickly as it appeared it was gone and the wagon lurched forward, none worse for the wear .',\n",
       " 'But money got the better of him, as money does to us all, so he pulled a quick and very illegal U-turn and headed toward the merchant in the square downtown.',\n",
       " 'He slammed on his brakes and the car skidded toward the curb, his fender a quarter inch from grazing the bumper of the car ahead and for a second, he wondered about how a man with confederate flag and second amendment stickers on a wood paneled station wagon might react in a wreck type situation and well, he probably dodged a bullet there.',\n",
       " 'Full of bar patrons pretending not to be drunk while cops watch with their beady cop eyes concealed in wraparound sunglasses, leaning on bicycles in spandex shorts, looking for a stumble or hint of horseplay like predators seeking movement in a tangled jungle, and when they pounce it is not with their teeth sinking into flesh but rather handcuf fs sinking into freedom.',\n",
       " '‘RLC,’ sat atop what appeared to be a slogan: ‘Where lost objects go to be found.’ The words cast in lowercase blackletter that gleamed luminescent gold shot through with clean lines of green giving off a real Saint Patrick’ s Day at the goth club vibe.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"crime\", model, DF['sentence'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190fee1a-bbec-49f7-b09c-ba06f3c5e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totaltime: 0.019928932189941406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['--- Your delivery is on the desk, run along now, wouldn’ t want you to be too late.',\n",
       " 'An average all day delivery shift in a perpetually collapsing economy veering dangerously toward what some might consider the end, while others, like our driver here, would consider an *improvement*.',\n",
       " 'So, time to get the delivery and peace out, he decided.',\n",
       " 'He drove, as most delivery drivers do, in a manner that was both antagonistic to public safety and necessary to make enough money to live another day and do the same thing all over again.',\n",
       " 'The chime seemed different on the last delivery he made.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(\"delivery\", model, DF['sentence'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835a8c2-ea7d-487e-ae0e-55ed1daac68c",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "**&nbsp;1. Examine the results**<br>\n",
    "From the results, the search engine appears to function effectively. It successfully retrieved sentences that contained specific keywords such as `overseer`, `crime`, and `delivery`. The search engine produced relevant results for each query, including the term and its contextual usage within the text.\n",
    "\n",
    "1. **\"Overseer\" Query**: The search returned sentences mentioning \"overseer\" and related contexts, such as the character's interaction and description. This indicates good precision in finding text related to the keyword.\n",
    "2. **\"Crime\" Query**: The search engine retrieved sentences discussing scenarios involving potential criminal activity, capturing the broader context of \"crime,\" which suggests good comprehension of query relevance.\n",
    "3. **\"Delivery\" Query**: It returned sentences that accurately describe aspects of delivery, from the experience of a delivery driver to specific instances of deliveries, showing the system's ability to associate the query with various uses of the term in the text.\n",
    "\n",
    "Overall, the search engine works well, with fast response times and accurate text retrieval based on the input queries, demonstrating relevance and efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca01e200-a713-4056-a462-f8760a7a96b0",
   "metadata": {},
   "source": [
    "## Create Text Summaries\n",
    "\n",
    "* Create a human summary of the text.\n",
    "* Create text summaries using LSA, TextRank, and Topic Modeling.\n",
    "* Assess those summaries using the Rouge-N analyzer.\n",
    "* Which summary was the best when compared to the human summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75f129e8-ca08-4bf5-b2ff-10f50971a5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_summary = \"A crumbling shack in the Mojave desert houses the heartbeat at the center of the universe. \\\n",
    "Long ago, the heart was diminished to a parasite when new spoiled gods built of the more distasteful human energies \\\n",
    "usurped the throne and began their own type of reign. They battled and bickered and those arguments translated to our world \\\n",
    "in the form of tragedies, mass rituals, and monied black magic. Now, it seems that history is coming to a head and our spoiled gods \\\n",
    "are fighting harder than they have ever fought before. Dead in the center of all of this are two humans. One an unwitting delivery \\\n",
    "driver turned host for the parasitic heart. The other a disgraced drug addicted cop who went searching for the driver on behalf of \\\n",
    "his family. Everything else, we will discover together.\"\n",
    "\n",
    "chatgpt_summary = \"Episode 1: The Return of the Overseer follows the story of a delivery driver who receives an unusual order \\\n",
    "that takes him to Reynold’s Limited Curiosities, a mysterious shop. The driver encounters a strange, sentient desk in the shop, \\\n",
    "which is inhabited by a sphinx-like creature. Despite warnings from an enigmatic voice, the driver approaches the desk and is attacked \\\n",
    "by the creature, only to be saved by multicolored worms that emerge from the light fixtures. The creature is destroyed, and \\\n",
    "a glowing figure appears before the driver, guiding him to a room filled with jars containing strange contents. \\\n",
    "The figure disappears, leaving the driver bewildered. He quickly grabs his delivery and flees the shop, \\\n",
    "experiencing strange phenomena and feeling disconnected from reality.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6addd-b578-4af2-a128-e7134199f480",
   "metadata": {},
   "source": [
    "### Text Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d15ea7cb-4edd-44dd-9353-4e0de107b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The car stopped, rocking on its axles and for a second, Time evened back out and the world settled back where it belonged, as in *anywhere but on him * and he pressed the flashing red ACCEPT at the bottom of the screen. He did this for a few moments as the sound slowly faded and finally he could hear the buzzing fluorescent lights, blinking on the ceiling like morse code, both inside and outside the door and yeah they were louder than they should have been but that was barely noticeable compared to the alarm bell nightmare the preceding minutes wrought and this helped restore enough normalcy to the situation that our Driver felt as comfortable as he was going to get with walking inside. He chose to ignore the voice because it did not seem to be interested in, or courteous enough, to try making any sort of sense and he didn’ t know where this buzz he felt was coming from, but he could fucking dig it and this lady and her nonsense was coming dangerously close to ruining it for him and that is a particular type of sin our Driver cannot abide. Instead of neck deep in the bowl for a meal of wooden slop, it stared at our Driver , eyes fixated on his, lips curled in a menacing snarl, teeth, still dripping with drool and filth, bared as if to say: --- (everywhere voice overlaid same as back in the core of Wireland) The next time our paths cross, I *will* eat you. Our Driver stared back at the sphinx, afraid to approach the desk though that was the only thing he could think of doing.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_summary_sentences = 5\n",
    "# be sure to put in one big long string \n",
    "# this will parse things into sentences for summarization\n",
    "parser = PlaintextParser.from_string(text, Tokenizer(LANGUAGE))\n",
    "# builds a summarizer with a stemmer (which grabs english from above)\n",
    "summarizer = TextRankSummarizer(stemmer)\n",
    "# add the stops for the language we set (english)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "tr_sum = []\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentences):\n",
    "    tr_sum.append(str(sentence))\n",
    "    \n",
    "tr_sum = \" \".join(tr_sum)\n",
    "\n",
    "tr_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d74351-4194-4978-bc0b-5b2dcc82d31d",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552e2813-5859-411d-a57a-64a1e92011d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normally this meant sitting on a zoom call with other corporate lawyers discussing the cost benefit of either ignoring that pesky business of sometimes the gas tank just fucking explodes on the new Kia Soul {redacted} model or doing a recall, [not in terms of human lives mind you, but *settlements and tax write offs*,] and *not* driving 65 through a school zone to get to the curiosities shoppe across town. ‘RLC,’ sat atop what appeared to be a slogan: ‘Where lost objects go to be found.’ The words cast in lowercase blackletter that gleamed luminescent gold shot through with clean lines of green giving off a real Saint Patrick’ s Day at the goth club vibe. The chest curved upward but still dipped down in a submissive pose, human breasts hanging down, nipples wrapped by the lips of suckling pig heads attached to the bodies of gluttonous babies, front arms bent outward behind the creatures awkwardly cradling them, palms outstretched before her supporting the weight of it all. The growl reaching an apex and then— —The bulbs on the ceiling burst, sending shards of glass and phosphor raining down in the dark and Our driver watched as writhing sectioned technicolor worms fell from the fixtures, radiating rainbow glow and landing hard and heavy with wet smacking noises. Instead of neck deep in the bowl for a meal of wooden slop, it stared at our Driver , eyes fixated on his, lips curled in a menacing snarl, teeth, still dripping with drool and filth, bared as if to say: --- (everywhere voice overlaid same as back in the core of Wireland) The next time our paths cross, I *will* eat you.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = LsaSummarizer(stemmer)\n",
    "summarizer.stop_words = get_stop_words(LANGUAGE)\n",
    "\n",
    "lsa_sum = []\n",
    "\n",
    "for sentence in summarizer(parser.document, num_summary_sentences):\n",
    "    lsa_sum.append(str(sentence))\n",
    "    \n",
    "lsa_sum = \" \".join(lsa_sum)\n",
    "\n",
    "lsa_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a148c1b-445c-4fb7-8354-7dee2f64f36e",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d13fbcb9-9e84-4266-9161-ead72dfd4234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And through that film, the fluorescent lights strobed and stalled, going bright to dim to dark every couple of seconds and had he been inside, he would have noticed the buzzing bug murder zap noise that accompanied each phase of fluorescence creating a smothering atmosphere that would’ve made his jaw clench tight, and his hair stand on end. As the sun set over his anywhere town USA in a wash of pastels, night began seeping into the sky like ink blots on a Rorschach test, appearing to our driver as butterflies or genocides depending on his mood and the traffic and - both changed minute to minute. He crossed the threshold slowly and as he did a bell rang, presumably a way of letting whoever worked here know they had a visitor , but it must have been broken or… altered, because it rang so loudly , he swore he felt his eardrums vibrate and pulse with each pump of his quickening heart. If you are the impatient sort, come to the back room, this is inadvisable and may lead to stress and night terrors but will garner you the attention you seek. He had a sense for when an order needed to be dropped because the money wasn’ t going to equal the hassle and this one ticked all the boxes.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember all the stuff from earlier that was loaded\n",
    "# Create a dictionary representation of the documents.\n",
    "# use our list of sentences from earlier\n",
    "processed_sentences = [preprocess(sent) for sent in sentences]\n",
    "# create the vocabulary list \n",
    "dictionary = Dictionary(processed_sentences)\n",
    "# convert to a term by document matrix \n",
    "corpus = [dictionary.doc2bow(sent) for sent in processed_sentences]\n",
    "\n",
    "# Train the topic model\n",
    "LDAmodel = LdaModel(corpus = corpus, \n",
    "                id2word = dictionary,\n",
    "                iterations = 400, \n",
    "                num_topics = 10,\n",
    "                random_state = 100,\n",
    "                update_every = 1,\n",
    "                chunksize = 100,\n",
    "                passes = 10,\n",
    "                alpha = 'auto',\n",
    "                per_word_topics = True)\n",
    "                \n",
    "probs = [LDAmodel.get_document_topics(sentence) for sentence in corpus]\n",
    "\n",
    "save_probs = []\n",
    "i = 0 # looping variable\n",
    "for document in probs:\n",
    "  for (topic, prob) in document:\n",
    "    if topic == 0: # this is the topic zero but you can pick another one\n",
    "      save_probs.append((sentences[i], prob))\n",
    "  i = i + 1\n",
    "      \n",
    "DF = pd.DataFrame(save_probs, columns = [\"sentence\", \"prob\"])\n",
    "\n",
    "topic_sum = \" \".join(DF.sort_values(by = [\"prob\"], ascending = False)[0:num_summary_sentences].sentence)\n",
    "\n",
    "topic_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733a05d-1952-4716-84b0-418eca4aa804",
   "metadata": {},
   "source": [
    "### Rouge-N analyzer\n",
    "Assess those summaries using the Rouge-N analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "705d74e3-32cc-4ca1-92db-9b1d8e896fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################## Compared to overall podcast paragraph ##############################\n",
      "#### TextRank ####\n",
      "rouge1 Precision: 0.20 Recall: 0.42 fmeasure: 0.27\n",
      "\n",
      "#### LSA ####\n",
      "rouge1 Precision: 0.19 Recall: 0.39 fmeasure: 0.26\n",
      "\n",
      "#### Topic Modeling ####\n",
      "rouge1 Precision: 0.23 Recall: 0.36 fmeasure: 0.28\n",
      "\n",
      "############################## Compared to ChatGpt ##############################\n",
      "#### TextRank ####\n",
      "rouge1 Precision: 0.18 Recall: 0.40 fmeasure: 0.25\n",
      "\n",
      "#### LSA ####\n",
      "rouge1 Precision: 0.18 Recall: 0.39 fmeasure: 0.24\n",
      "\n",
      "#### Topic Modeling ####\n",
      "rouge1 Precision: 0.19 Recall: 0.34 fmeasure: 0.24\n"
     ]
    }
   ],
   "source": [
    "# build a blank model\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "# add the gold standard and summary you want to compare\n",
    "# scores = scorer.score(gold_standard, summary)\n",
    "# print the scores\n",
    "# print_rouge_score(scores)\n",
    "\n",
    "# compare to overall podcast paragraph\n",
    "print(\"\\n############################## Compared to overall podcast paragraph ##############################\")\n",
    "print(\"#### TextRank ####\")\n",
    "print_rouge_score(scorer.score(human_summary, tr_sum))\n",
    "\n",
    "print(\"\\n#### LSA ####\")\n",
    "print_rouge_score(scorer.score(human_summary, lsa_sum))\n",
    "\n",
    "print(\"\\n#### Topic Modeling ####\")\n",
    "print_rouge_score(scorer.score(human_summary, topic_sum))\n",
    "\n",
    "# compare to chat gpt\n",
    "print(\"\\n############################## Compared to ChatGpt ##############################\")\n",
    "print(\"#### TextRank ####\")\n",
    "print_rouge_score(scorer.score(chatgpt_summary, tr_sum))\n",
    "\n",
    "print(\"\\n#### LSA ####\")\n",
    "print_rouge_score(scorer.score(chatgpt_summary, lsa_sum))\n",
    "\n",
    "print(\"\\n#### Topic Modeling ####\")\n",
    "print_rouge_score(scorer.score(chatgpt_summary, topic_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d0b26-700e-4d51-bc17-659dc22e661a",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "**&nbsp;1. Which summary was the best when compared to the human summary?**<br>\n",
    "Based on the `Rouge-N scores` provided, the best summary compared to the human-generated summary was the one generated by __Topic Modeling__. It had the highest **fmeasure** of **0.28** compared to the _TextRank(0.27)_ and _LSA(0.26)_ summaries. This suggests that the Topic Modeling summarizer was more effective in capturing the essential points and reflecting the content and style of the human summary.\n",
    "However, TextRank(0.25) performed better compared to the Topic Modeling(0.24) and LSA(0.24) summaries against ChatGpt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b2641-b128-4d7c-ba5c-71b104766145",
   "metadata": {},
   "source": [
    "### Visualization of topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "507f0142-a5a2-49d4-a381-c9087c78ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim_models.prepare(LDAmodel, corpus, dictionary, n_jobs = 1)\n",
    "pyLDAvis.save_html(vis, 'LDA_Visualization.html') ##saves the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac6092-d599-4334-a65a-bb7f512bac81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 (tfd)",
   "language": "python",
   "name": "tfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
